{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0577a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train = pd.read_csv(r'C:\\AI_BOOTCAMP\\AWS\\mart_sale\\train.csv')\n",
    "train.head()\n",
    "train.shape\n",
    "\n",
    "test = pd.read_csv(r'C:\\AI_BOOTCAMP\\AWS\\mart_sale\\test.csv')\n",
    "test.head()\n",
    "test.shape\n",
    "\n",
    "train.isnull().sum()\n",
    "test.isnull().sum()\n",
    "\n",
    "train.describe()\n",
    "\n",
    "correl = train.corr()\n",
    "ax = plt.subplots(figsize=(15, 9))\n",
    "sns.heatmap(correl, vmax=0.8, square=True)\n",
    "\n",
    "train.head()\n",
    "train.Item_Fat_Content.value_counts()\n",
    "train.Item_Type.value_counts()\n",
    "train.Outlet_Identifier.value_counts()\n",
    "train.Outlet_Size.value_counts()\n",
    "train.Outlet_Location_Type.value_counts()\n",
    "train.Outlet_Type.value_counts()\n",
    "train.head()\n",
    "train.isnull().sum()\n",
    "\n",
    "train.Item_Weight.hist(bins=50)\n",
    "train.Outlet_Size.hist(bins=50)\n",
    "train.Outlet_Size.value_counts()\n",
    "Item_Sales = train.Item_Outlet_Sales\n",
    "data = train.append(test)\n",
    "data.shape\n",
    "data.isnull().sum()\n",
    "data.isnull().sum()\n",
    "correlation = data.corr()\n",
    "sns.heatmap(correlation, vmax=0.8, square=True)\n",
    "data.apply(lambda x: len(x.unique()))\n",
    "data.dtypes\n",
    "data.dtypes.index\n",
    "categorical_columns = [x for x in data.dtypes.index if data.dtypes[x] == 'object']\n",
    "categorical_columns\n",
    "categorical_columns = [x for x in categorical_columns if x not in ['Item_Identifier', 'Outlet_Identifier']]\n",
    "categorical_columns\n",
    "for col in categorical_columns:\n",
    "    print('frequency of categories for variable')\n",
    "    print(data[col].value_counts())\n",
    "\n",
    "data.Item_Weight.fillna(data.Item_Weight.mean(), inplace=True)\n",
    "from scipy.stats import mode\n",
    "data.Outlet_Size = data.Outlet_Size.map({'Small': 0, 'Medium': 1, 'High': 2})\n",
    "outlet_size_mode = data.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=(lambda x: mode(x).mode[0]))\n",
    "miss_bool = data['Outlet_Size'].isnull()\n",
    "data.loc[miss_bool, 'Outlet_Size'] = data.loc[miss_bool, 'Outlet_Type'].apply(lambda x: outlet_size_mode[x])\n",
    "\n",
    "for i in data.dtypes.index:\n",
    "    if len(data[i].value_counts()) < 30:\n",
    "        print(i, \"\\n\", data[i].value_counts())\n",
    "\n",
    "data.pivot_table(index='Outlet_Type', values='Item_Outlet_Sales')\n",
    "data.Item_Visibility.hist(bins=50)\n",
    "data.Item_Visibility.mean()\n",
    "data.loc[data['Item_Visibility'] == 0, 'Item_Visibility'] = data.Item_Visibility.mean()\n",
    "data.Item_Type.value_counts()\n",
    "data['Item_Type_Combined'] = data.Item_Identifier.apply(lambda x: x[0:2])\n",
    "data['Item_Type_Combined'].value_counts()\n",
    "data['Item_Type_Combined'] = data.Item_Type_Combined.map({'FD': 'Food and Drinks', 'NC': 'Non-Consumable', 'DR': 'Drinks'})\n",
    "data['Item_Type_Combined'].value_counts()\n",
    "data['Outlet_Years'] = 2013 - data['Outlet_Establishment_Year']\n",
    "data['Outlet_Years'].describe()\n",
    "data.Item_Fat_Content.value_counts()\n",
    "data.Item_Fat_Content = data.Item_Fat_Content.replace({'LF': 'Low Fat', 'reg': 'Regular', 'low fat': 'Low Fat'})\n",
    "data.Item_Fat_Content.value_counts()\n",
    "data.loc[data['Item_Type_Combined'] == 'Non-Consumable', 'Item_Fat_Content'] = 'Non-Edible'\n",
    "data.Item_Fat_Content.value_counts()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "data['Outlet'] = lb.fit_transform(data['Outlet_Identifier'])\n",
    "var = ['Item_Fat_Content', 'Outlet_Location_Type', 'Outlet_Type', 'Outlet_Size', 'Item_Type_Combined']\n",
    "lb = LabelEncoder()\n",
    "for item in var:\n",
    "    data[item] = lb.fit_transform(data[item])\n",
    "data.drop(['Outlet_Establishment_Year', 'Item_Type'], inplace=True, axis=1)\n",
    "\n",
    "Item_Sales = data.Item_Outlet_Sales\n",
    "train = data.iloc[:8523, :]\n",
    "test = data.iloc[8523:, :]\n",
    "test.drop('Item_Outlet_Sales', inplace=True, axis=1)\n",
    "\n",
    "target = 'Item_Outlet_Sales'\n",
    "IDcol = ['Item_Identifier', 'Outlet_Identifier']\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "\n",
    "def modelfit(alg, dtrain, dtest, predictor, target, IDcol, filename):\n",
    "    alg.fit(dtrain[predictor], dtrain[target])\n",
    "    prediction = alg.predict(dtrain[predictor])\n",
    "    cv_score = model_selection.cross_val_score(alg, dtrain[predictor], dtrain[target], cv=20, scoring='neg_mean_squared_error')\n",
    "    cv_score = np.sqrt(np.abs(cv_score))\n",
    "    print(np.sqrt(metrics.mean_squared_error(dtrain[target].values, prediction))\n",
    "    print(\"CV_SCORE : mean - %.4g | std - %.4g | max - %.4g | min - %.4g\" % (np.mean(cv_score), np.std(cv_score), np.max(cv_score), np.min(cv_score)))\n",
    "    dtest[target] = alg.predict(dtest[predictor])\n",
    "    IDcol.append(target)\n",
    "    submission = pd.DataFrame({x: dtest[x] for x in IDcol})\n",
    "    submission.to_csv(\"C:\\\\Users\\\\rishav\\\\Desktop\\\\nart_sale_prediction\\\\\" + filename, index=False)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "predictor = [x for x in train.columns if x not in [target] + IDcol]\n",
    "alg1 = LinearRegression()\n",
    "modelfit(alg1, train, test, predictor, target, IDcol, 'alg1.csv')\n",
    "\n",
    "predictors = [x for x in train.columns if x not in [target] + IDcol]\n",
    "alg2 = Ridge(alpha=0.05, normalize=True)\n",
    "modelfit(alg2, train, test, predictors, target, IDcol, 'alg2.csv')\n",
    "coef2 = pd.Series(alg2.coef_, predictors).sort_values()\n",
    "coef2.plot(kind='bar', title='Model Coefficients')\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "predictors = [x for x in train.columns if x not in [target] + IDcol]\n",
    "alg3 = DecisionTreeRegressor(max_depth=15, min_samples_leaf=100)\n",
    "modelfit(alg3, train, test, predictors, target, IDcol, 'alg3.csv')\n",
    "coef3 = pd.Series(alg3.feature_importances_, predictors).sort_values(ascending=False)\n",
    "coef3.plot(kind='bar', title='Feature Importances')\n",
    "\n",
    "predictors = ['Item_MRP', 'Outlet_Type', 'Outlet', 'Outlet_Years']\n",
    "alg4 = DecisionTreeRegressor(max_depth=8, min_samples_leaf=150)\n",
    "modelfit(alg4, train, test, predictors, target, IDcol, 'alg4.csv')\n",
    "coef4 = pd.Series(alg4.feature_importances_, predictors).sort_values(ascending=False)\n",
    "coef4.plot(kind='bar', title='Feature Importances')\n",
    "\n",
    "predictors = ['Item_MRP', 'Outlet_Type', 'Outlet', 'Outlet_Years']\n",
    "alg4 = DecisionTreeRegressor(max_depth=8, min_samples_leaf=150)\n",
    "modelfit(alg4, train, test, predictors, target, IDcol, 'alg4.csv')\n",
    "coef4 = pd.Series(alg4.feature_importances_, predictors).sort_values(ascending=False)\n",
    "coef4.plot(kind='bar', title='Feature Importances')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c24b338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334bd94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
